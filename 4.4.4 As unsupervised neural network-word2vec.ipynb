{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is similarity? Word2vec strengths and weaknesses\n",
    "\n",
    "Keep in mind that word2vec operates on the assumption that frequent proximity indicates similarity, but words can be \"similar\" in various ways. They may be conceptually similar (\"royal\", \"king\", and \"throne\"), but they may also be functionally similar (\"tremendous\" and \"negligible\" are both common modifiers of \"size\"). Here is a more detailed exploration, [with examples](https://quomodocumque.wordpress.com/2016/01/15/messing-around-with-word2vec/), of what \"similarity\" means in word2vec.\n",
    "\n",
    "One cool thing about word2vec is that it can identify similarities between words _that never occur near one another in the corpus_. For example, consider these sentences:\n",
    "\n",
    "\"The dog played with an elastic ball.\"\n",
    "\"Babies prefer the ball that is bouncy.\"\n",
    "\"I wanted to find a ball that's elastic.\"\n",
    "\"Tracy threw a bouncy ball.\"\n",
    "\n",
    "\"Elastic\" and \"bouncy\" are similar in meaning in the text but don't appear in the same sentence. However, both appear near \"ball\". In the process of nudging the vectors around so that \"elastic\" and \"bouncy\" are both near the vector for \"ball\", the words also become nearer to one another and their similarity can be detected.\n",
    "\n",
    "For a while after it was introduced, [no one was really sure why word2vec worked as well as it did](https://arxiv.org/pdf/1402.3722v1.pdf) (see last paragraph of the linked paper). A few years later, some additional math was developed to explain word2vec and similar models. If you are comfortable with both math and \"academese\", have a lot of time on your hands, and want to take a deep dive into the inner workings of word2vec, [check out this paper](https://arxiv.org/pdf/1502.03520v7.pdf) from 2016.  \n",
    "\n",
    "One of the draws of word2vec when it first came out was that the vectors could be used to convert analogies (\"king\" is to \"queen\" as \"man\" is to \"woman\", for example) into mathematical expressions (\"king\" + \"woman\" - \"man\" = ?) and solve for the missing element (\"queen\"). This is kinda nifty.\n",
    "\n",
    "A drawback of word2vec is that it works best with a corpus that is at least several billion words long. Even though the word2vec algorithm is speedy, this is a a lot of data and takes a long time! Our example dataset is only two million words long, which allows us to run it in the notebook without overwhelming the kernel, but probably won't give great results.  Still, let's try it!\n",
    "\n",
    "There are a few word2vec implementations in Python, but the general consensus is the easiest one to us is in [gensim](https://radimrehurek.com/gensim/models/word2vec.html). Now is a good time to `pip install gensim` if you don't have it yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to clean text.\n",
    "def text_cleaner(text):\n",
    "    \n",
    "    # Visual inspection shows spaCy does not recognize the double dash '--'.\n",
    "    # Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    \n",
    "    # Get rid of headings in square brackets.\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    \n",
    "    # Get rid of chapter titles.\n",
    "    text = re.sub(r'Chapter \\d+','',text)\n",
    "    \n",
    "    # Get rid of extra whitespace.\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text[0:900000]\n",
    "\n",
    "\n",
    "# Import all the Austen in the Project Gutenberg corpus.\n",
    "austen = \"\"\n",
    "for novel in ['persuasion','emma','sense']:\n",
    "    work = gutenberg.raw('austen-' + novel + '.txt')\n",
    "    austen = austen + work\n",
    "\n",
    "# Clean the data.\n",
    "austen_clean = text_cleaner(austen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data. This can take some time.\n",
    "nlp = spacy.load('en')\n",
    "austen_doc = nlp(austen_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['for', 'daughter', 'eld', 'give', 'thing', 'tempt']\n",
      "We have 7771 sentences and 900000 tokens.\n"
     ]
    }
   ],
   "source": [
    "# Organize the parsed doc into sentences, while filtering out punctuation\n",
    "# and stop words, and converting words to lower case lemmas.\n",
    "sentences = []\n",
    "for sentence in austen_doc.sents:\n",
    "    sentence = [\n",
    "        token.lemma_.lower()\n",
    "        for token in sentence\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "    ]\n",
    "    sentences.append(sentence)\n",
    "\n",
    "\n",
    "print(sentences[20])\n",
    "print('We have {} sentences and {} tokens.'.format(len(sentences), len(austen_clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec(\n",
    "    sentences,\n",
    "    workers=4,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "    min_count=10,  # Minimum word count threshold.\n",
    "    window=6,      # Number of words around target word to consider.\n",
    "    sg=0,          # Use CBOW because our corpus is small.\n",
    "    sample=1e-3 ,  # Penalize frequent words.\n",
    "    size=300,      # Word vector length.\n",
    "    hs=1           # Use hierarchical softmax.\n",
    ")\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('benwick', 0.774645209312439), ('anne', 0.763766348361969), ('mr', 0.7580499649047852), ('louisa', 0.7522648572921753), ('room', 0.7368901968002319), ('charles', 0.7226456999778748), ('wentworth', 0.7104607820510864), ('avoid', 0.7049810886383057), ('sister', 0.7018667459487915), ('manner', 0.6996272802352905)]\n",
      "0.6889521905346276\n",
      "marriage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# List of words in model.\n",
    "vocab = model.wv.vocab.keys()\n",
    "\n",
    "print(model.wv.most_similar(positive=['lady', 'man'], negative=['woman']))\n",
    "\n",
    "# Similarity is calculated using the cosine, so again 1 is total\n",
    "# similarity and 0 is no similarity.\n",
    "print(model.wv.similarity('mr', 'mrs'))\n",
    "\n",
    "# One of these things is not like the other...\n",
    "print(model.doesnt_match(\"breakfast marriage dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly this model is not great â€“ while some words given above might possibly fill in the analogy woman:lady::man:?, most answers likely make little sense. You'll notice as well that re-running the model likely gives you different results, indicating random chance plays a large role here.\n",
    "\n",
    "We do, however, get a nice result on \"marriage\" being dissimilar to \"breakfast\", \"lunch\", and \"dinner\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drill 0\n",
    "\n",
    "Take a few minutes to modify the hyperparameters of this model and see how its answers change. Can you wrangle any improvements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(\n",
    "    sentences,\n",
    "    workers=6,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "    min_count=5,  # Minimum word count threshold.\n",
    "    window=8,      # Number of words around target word to consider.\n",
    "    sg=0,          # Use CBOW because our corpus is small.\n",
    "    sample=1e-3 ,  # Penalize frequent words.\n",
    "    size=300,      # Word vector length.\n",
    "    hs=1           # Use hierarchical softmax.\n",
    ")\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mr', 0.9172568321228027), ('clay', 0.8690119981765747), ('of', 0.8530237674713135), ('croft', 0.8522793650627136), ('hall', 0.8461040258407593), ('bright', 0.8445383310317993), ('smith', 0.8440250158309937), ('dalrymple', 0.8398169279098511), ('before', 0.8369473814964294), ('breed', 0.8336030840873718)]\n",
      "0.6617327050809527\n",
      "marriage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# List of words in model.\n",
    "vocab = model.wv.vocab.keys()\n",
    "\n",
    "print(model.wv.most_similar(positive=['lady', 'man'], negative=['woman']))\n",
    "\n",
    "# Similarity is calculated using the cosine, so again 1 is total\n",
    "# similarity and 0 is no similarity.\n",
    "print(model.wv.similarity('mr', 'mrs'))\n",
    "\n",
    "# One of these things is not like the other...\n",
    "print(model.doesnt_match(\"breakfast marriage dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example word2vec applications\n",
    "\n",
    "You can use the vectors from word2vec as features in other models, or try to gain insight from the vector compositions themselves.\n",
    "\n",
    "Here are some neat things people have done with word2vec:\n",
    "\n",
    " * [Visualizing word embeddings in Jane Austen's Pride and Prejudice](http://blogger.ghostweather.com/2014/11/visualizing-word-embeddings-in-pride.html). Skip to the bottom to see a _truly honest_ account of this data scientist's process.\n",
    "\n",
    " * [Tracking changes in Dutch Newspapers' associations with words like 'propaganda' and 'alien' from 1950 to 1990](https://www.slideshare.net/MelvinWevers/concepts-through-time-tracing-concepts-in-dutch-newspaper-discourse-using-sequential-word-vector-spaces).\n",
    "\n",
    " * [Helping customers find clothing items similar to a given item but differing on one or more characteristics](http://multithreaded.stitchfix.com/blog/2015/03/11/word-is-worth-a-thousand-vectors/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drill 1: Word2Vec on 100B+ words\n",
    "\n",
    "As we mentioned, word2vec really works best on a big corpus, but it can take half a day to clean such a corpus and run word2vec on it.  Fortunately, there are word2vec models available that have already been trained on _really_ big corpora. They are big files, but you can download a [pretrained model of your choice here](https://github.com/3Top/word2vec-api). At minimum, the ones built with word2vec (check the \"Architecture\" column) should load smoothly using an appropriately modified version of the code below, and you can play to your heart's content.\n",
    "\n",
    "Because the models are so large, however, you may run into memory problems or crash the kernel. If you can't get a pretrained model to run locally, check out this [interactive web app of the Google News model](https://rare-technologies.com/word2vec-tutorial/#bonus_app) instead.\n",
    "\n",
    "However you access it, play around with a pretrained model. Is there anything interesting you're able to pull out about analogies, similar words, or words that don't match? Write up a quick note about your tinkering and discuss it with your mentor during your next session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Google's pre-trained Word2Vec model.\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format ('https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('athletes', 0.7058197855949402)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on basketball and athlete\n",
    "model.most_similar(['athlete', 'basketball'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('skating', 0.651188850402832)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on figure skating and olympics\n",
    "model.most_similar(['skater', 'olympics'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Utah', 0.6033661961555481)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on United States and Idaho\n",
    "model.most_similar(['USA', 'Idaho'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Manitoba', 0.7741403579711914)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on Canada and Ontario\n",
    "model.most_similar(['Canada', 'Ontario'], topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems as though the model finds similar lemmas for words like athlete and skater. Also, it seems to be pretty good at identifiying simlar geographic regions within a country. One more test for this theory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DR_Congo', 0.7756456136703491)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on Africa and Congo\n",
    "model.most_similar(['Africa', 'Congo'], topn=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
