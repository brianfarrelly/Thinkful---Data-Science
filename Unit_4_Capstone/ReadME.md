# Unit 4 Capstone - Classifying classic authors by word usage

This capstone involves loading the text from 10 classic authors, and analyzing their word usage through tfidf vectorization.
A neural network and radom forest are then each used to attempt to classify the authors by their tfidf vectorization score per 
word. Spacy and NLTK are used to import the text and analyze the words, while sci-kit learn and H2O Flow are used to build the 
models and perform clustering. 

## Getting Started

The notebook created for this repository use iPython notebooks.

```
Jupyter notebook - https://ipython.org/install.html
```
```
scitkit-learn - https://scikit-learn.org/stable/install.html
```
```
spaCy - https://spacy.io/
```
```
NLTK (Natural Language Toolkit) - https://www.nltk.org/
```

## Built With

[Jupyter Notebook](https://ipython.org/) - Web framework used

[sci-kit learn](https://scikit-learn.org/stable/) - Machine Learning Library

[H2O Flow](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/flow.html)

## Authors 

Kyle Knoebel - https://www.linkedin.com/in/kyle-knoebel-ab846725/
