{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancer Diagnostics\n",
    "\n",
    "Using set of breast [cancer data](http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29), create a model to predict breast cancer. Also, what traits are most indicative of whether or not an individual will be diagnosed? The following is information necessary to understanding the dataset taken from the [dataset description link.](http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names)  \n",
    "\n",
    "## Dataset Description\n",
    "\n",
    "Attributes 2 through 10 have been used to represent instances.\n",
    "   Each instance has one of 2 possible classes: benign or malignant.\n",
    "\n",
    "   1. Wolberg,~W.~H., \\& Mangasarian,~O.~L. (1990). Multisurface method of \n",
    "      pattern separation for medical diagnosis applied to breast cytology. In\n",
    "      {\\it Proceedings of the National Academy of Sciences}, {\\it 87},\n",
    "      9193--9196.\n",
    "      -- Size of data set: only 369 instances (at that point in time)\n",
    "      -- Collected classification results: 1 trial only\n",
    "      -- Two pairs of parallel hyperplanes were found to be consistent with\n",
    "         50% of the data\n",
    "         -- Accuracy on remaining 50% of dataset: 93.5%\n",
    "      -- Three pairs of parallel hyperplanes were found to be consistent with\n",
    "         67% of data\n",
    "         -- Accuracy on remaining 33% of dataset: 95.9%\n",
    "\n",
    "   2. Zhang,~J. (1992). Selecting typical instances in instance-based\n",
    "      learning.  In {\\it Proceedings of the Ninth International Machine\n",
    "      Learning Conference} (pp. 470--479).  Aberdeen, Scotland: Morgan\n",
    "      Kaufmann.\n",
    "      -- Size of data set: only 369 instances (at that point in time)\n",
    "      -- Applied 4 instance-based learning algorithms \n",
    "      -- Collected classification results averaged over 10 trials\n",
    "      -- Best accuracy result: \n",
    "         -- 1-nearest neighbor: 93.7%\n",
    "         -- trained on 200 instances, tested on the other 169\n",
    "      -- Also of interest:\n",
    "         -- Using only typical instances: 92.2% (storing only 23.1 instances)\n",
    "         -- trained on 200 instances, tested on the other 169\n",
    "\n",
    "4. Relevant Information:\n",
    "\n",
    "   Samples arrive periodically as Dr. Wolberg reports his clinical cases.\n",
    "   The database therefore reflects this chronological grouping of the data.\n",
    "   This grouping information appears immediately below, having been removed\n",
    "   from the data itself:\n",
    "\n",
    "     - Group 1: 367 instances (January 1989)\n",
    "     - Group 2:  70 instances (October 1989)\n",
    "     - Group 3:  31 instances (February 1990)\n",
    "     - Group 4:  17 instances (April 1990)\n",
    "     - Group 5:  48 instances (August 1990)\n",
    "     - Group 6:  49 instances (Updated January 1991)\n",
    "     - Group 7:  31 instances (June 1991)\n",
    "     - Group 8:  86 instances (November 1991)\n",
    "     - Total:   699 points (as of the donated datbase on 15 July 1992)\n",
    "\n",
    "   Note that the results summarized above in Past Usage refer to a dataset\n",
    "   of size 369, while Group 1 has only 367 instances.  This is because it\n",
    "   originally contained 369 instances; 2 were removed.  The following\n",
    "   statements summarizes changes to the original Group 1's set of data:\n",
    "   \n",
    "\n",
    "5. Number of Instances: 699 (as of 15 July 1992)\n",
    "\n",
    "\n",
    "6. Number of Attributes: 10 plus the class attribute\n",
    "\n",
    "\n",
    "7. Attribute Information: (class attribute has been moved to last column)\n",
    "\n",
    "\n",
    "   Attribute                     Domain\n",
    "   -- -----------------------------------------\n",
    "   1. Sample code number            id number\n",
    "   2. Clump Thickness               1 - 10\n",
    "   3. Uniformity of Cell Size       1 - 10\n",
    "   4. Uniformity of Cell Shape      1 - 10\n",
    "   5. Marginal Adhesion             1 - 10\n",
    "   6. Single Epithelial Cell Size   1 - 10\n",
    "   7. Bare Nuclei                   1 - 10\n",
    "   8. Bland Chromatin               1 - 10\n",
    "   9. Normal Nucleoli               1 - 10\n",
    "   10. Mitoses                       1 - 10\n",
    "   11. Class:                        (2 for benign, 4 for malignant)\n",
    "\n",
    "8. Missing attribute values: 16\n",
    "\n",
    "   There are 16 instances in Groups 1 to 6 that contain a single missing \n",
    "   (i.e., unavailable) attribute value, now denoted by \"?\".  \n",
    "\n",
    "9. Class distribution:\n",
    " \n",
    "   Benign: 458 (65.5%)\n",
    "   Malignant: 241 (34.5%)\n",
    "\n",
    "## Clean/Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1   2   3   4   5   6   7   8   9   10\n",
       "0  1000025   5   1   1   1   2   1   3   1   1   2\n",
       "1  1002945   5   4   4   5   7  10   3   2   1   2\n",
       "2  1015425   3   1   1   1   2   2   3   1   1   2\n",
       "3  1016277   6   8   8   1   3   4   3   7   1   2\n",
       "4  1017023   4   1   1   3   2   1   3   1   1   2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and show format\n",
    "url=\"http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\"\n",
    "df=pd.read_csv(url, header=None, error_bad_lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is already organized in this format, the columns will not be renamed and the Attribute Domain information in the dataset description used to analyze the results at the end. \n",
    "\n",
    "In addition, the dataset description shows that at least 2 other analyses have attempted to describe portions of the data through hyperplanes. Since this method has been used before, and much of the data relates to microbiological bodies/processes unknown to this author, a gradient boosting method will be used to analyze the data and find which traits are most indicative of a positive (malignant) diagnosis. \n",
    "\n",
    "The pd.getdummies() function will be used on Column 10, which shows a benign or malignant diganosis, in order to get a binary format for the model. \n",
    "\n",
    "Finally, there are some mentions of '?' in the data. Since these values are unknown and would skew the analysis, these rows will be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with '?'\n",
    "df=df[df.iloc[0:10]!='?']\n",
    "df=df.dropna()\n",
    "# run get dummies on column 10\n",
    "df[10]=pd.get_dummies(df[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting to Analyze Breast Cancer Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# set predictor and outcome data\n",
    "y = df[10]\n",
    "X = df.drop([0, 10], 1)\n",
    "# create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "# We'll make 200 iterations, use 2-deep trees, and set our loss function to exponential \n",
    "params={'n_estimators': 200, \n",
    "    'max_depth': 2, \n",
    "    'loss': 'exponential'}\n",
    "# Initialize and fit the model.\n",
    "gbr = ensemble.GradientBoostingClassifier(**params)\n",
    "gbr.fit(X_train, y_train)\n",
    "gbr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = gbr.feature_importances_\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
