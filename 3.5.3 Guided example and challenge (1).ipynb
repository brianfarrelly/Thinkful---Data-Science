{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boost guided example\n",
    "\n",
    "Having walked through gradient boost by hand, now let's try it with SKlearn.  We'll still use the European Social Survey Data, but now with a categorical outcome: Whether or not someone lives with a partner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()\n",
    "\n",
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're now working with a binary outcome, we've switched to a classifier.  Now our loss function can't be the residuals.  Our options are \"deviance\", or \"exponential\".  Deviance is used for logistic regression, and we'll try that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04650845608292417\n",
      "Percent Type II errors: 0.17607746863066012\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06257668711656442\n",
      "Percent Type II errors: 0.18527607361963191\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike decision trees, gradient boost solutions are not terribly easy to interpret on the surface.  But they aren't quite a black box.  We can get a measure of how important various features are by counting how many times a feature is used over the course of many decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that age and happiness are the most important features in predicting whether or not someone lives with a partner.\n",
    "\n",
    "### DRILL: Improve this gradient boost model\n",
    "\n",
    "While this model is already doing alright, we've seen from the Type I and Type II error rates that there is definitely room for improvement.  Your task is to see how low you can get the error rates to go in the test set, based on your model in the training set.  Strategies you might use include:\n",
    "\n",
    "* Creating new features\n",
    "* Applying more overfitting-prevention strategies like subsampling\n",
    "* More iterations\n",
    "* Trying a different loss function\n",
    "* Changing the structure of the weak learner: Allowing more leaves in the tree, or other modifications\n",
    "\n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a correlation matrix wil be run to see how the features correlate to one another and if any features can be combined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cntry</th>\n",
       "      <th>idno</th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>partner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CH</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CH</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CH</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CH</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cntry  idno  year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  \\\n",
       "0    CH   5.0     6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   \n",
       "1    CH  25.0     6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   \n",
       "2    CH  26.0     6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   \n",
       "3    CH  28.0     6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   \n",
       "4    CH  29.0     6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   \n",
       "\n",
       "   gndr  agea  partner  \n",
       "0   2.0  60.0      1.0  \n",
       "1   2.0  59.0      1.0  \n",
       "2   1.0  24.0      2.0  \n",
       "3   2.0  64.0      1.0  \n",
       "4   2.0  55.0      1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1b567d30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEaCAYAAADkL6tQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmcXFWZ//HPNyEQSFjCMsoewLDJTtgUERj23REGUEdQFEERgZ/OOOOIEUZEcXQcUTAigisiyqKyC4jsSQg7BJBFEGacCAhIgCT9/P44p0ylqOqurntvdVf3982rXl19697nnu40deqsjyICMzOzZsYMdQHMzGz4ciVhZmYtuZIwM7OWXEmYmVlLriTMzKwlVxJmZtaSKwkzs2FE0rmS/iTpvhavS9J/S3pU0j2Stqp77QhJj+THEWWUx5WEmdnwch6wVz+v7w1MyY+jgbMAJK0IfA7YDtgW+JykSUUL40rCzGwYiYgbgef6OeVA4PuR3AasIGlVYE/gmoh4LiKeB66h/8qmLa4kzMx6y+rAU3XfP52PtTpeyBJFAwxX8+c+Vvp+IwdvdXzZIf9mDKok7nz6Kok7rgc/Xyygmi1oXo+FlcQFWEbV/C8qVfP3tlSFfxd/idcriXv5Hy4v/MsYzPvNkqus9xFSN1HN9IiYPojbNStv9HO8kBFbSZiZdU1f+x8UcoUwmEqh0dPAmnXfrwE8k4/v3HD8hgL3AdzdZGZWXPS1/yjuMuD9eZbT9sBfIuJZ4CpgD0mT8oD1HvlYIW5JmJkV1Vdet66kn5BaBCtLepo0Y2kcQEScDVwO7AM8CrwCfCC/9pykU4EZOdQpEdHfAHhbXEmYmRUU5bQQcqw4fIDXA/hYi9fOBc4trTB0sbtJ0i0tjp8n6eBulcPMrHR9fe0/ekzXWhIR8bZu3cvMrKsWzh/qElSmmy2Jl/NXSTpT0gOSfg38Xd05T0j6vKQ7Jd0racN8fEVJl+Ql6LdJ2qxb5TYzG1B3B667aihmN70L2ADYFPgw0NjCmBsRW5GWmn8yH/s8MDsiNgP+Dfh+l8pqZjawEdzdNBSVxE7ATyJiYUQ8A1zX8Pov8tdZwOT8fEfgBwARcR2wkqTlGwNLOlrSTEkzz/n+TyopvJlZo4i+th+9ZqhmN/W3CvC1/HUhi8rX1krC+kUqVay4NjNrqgdbCO0aipbEjcBhksbmTal2afOa9wJI2pnUJfVidUU0MxuEETwmMRQtiYuBXYF7gYeB37ZxzTTge5LuIS0eKWWfdDOzUozg2U3dnAI7MX8N4LgW50yuez6TvA9JXjV4YOWFNDPrxAjubvKKazOzonqwG6ldriTMzIpyS8LMzFqJCnOKDDVXEmZmRS1cMNQlqMyIrSSqyCJ30Z3/XXrMmr23PLaSuEtrXCVxq/RSRRnIltTYSuJGRRnvoLoMcgsr6kN/uaJMiAAThvPfssckzMyspUFkpus1riTMzIpyS8LMzFry7CYzM2vJLQkzM2tpgWc3DTuSxsZInpxsZj1jJL8VdWUXWEmnSvpE3fdfkHS8pE9JmpEzzn2+7vVLJM2SdL+ko+uOvyzpFEm3Azt0o+xmZgNy0qHCvkveuVXSGOAw4H+BKcC2wBbA1pJ2yud/MCK2BqYCx0taKR+fANwXEdtFxE1dKruZWf+8VXgxEfGEpD9L2hJ4EzAb2AbYIz8HmEiqNG4kVQzvysfXzMf/TEpE9PNW98mtjqMBNpu0KZMnrlXBT2Nm1qAHWwjt6uaYxDnAkcCbgXOBvwe+GBHfrj8pJxXaDdghIl6RdAMwPr/8an/jEPWZ6Q5caz9npjOz7ujBFkK7ullJXAycAowD3gMsAE6V9KOIeFnS6sB8YHng+VxBbAhs38UympkNnvduKi4iXpd0PfBCbg1cLWkj4Na8P83LwPuAK4Fjcha6OcBt3SqjmVlH3N1UXB6w3h44pHYsIr4OfL3J6Xs3i1HLbmdmNqyM4EqiW1NgNwYeBX4TEY90455mZl3j2U3FRMQDwLrduJeZWdeN4JZEz664NjMbNjxwbWZmLfVgN1K7RmwlMYbyM3pVlT0O4IrZZ1USd8MND64k7pJjqvvTWWHchEriPrvglUriThg7fuCTOjR3wcuVxF13yRUrifuu+ctVEhfg/LFzK4tdmLubzMysJVcSZmbWUozcDR66tcGfmdnIVfIusJL2kjRH0qOSPt3k9a9Juis/Hpb0Qt1rC+teu6zoj+aWhJlZUSXObpI0FvgmsDvwNDBD0mV5KQEAEXFi3fkfB7asCzEvIrYoqzxuSZiZFVVuS2Jb4NGIeCwiXgcuAA7s5/zDgZ+U8FM0VWklIWkFSR8d4JwtJO3TRqydJb2tvNKZmZUkov3HwFYHnqr7/ul87A0krQ2sA1xXd3i8pJmSbpN0UKc/Uk3VLYkVgH4rCVLCoQErCWBnwJWEmQ0/g2hJSDo6v4nXHkc3RGs2f79V7XIYcFFDCoW1ImIqabft/5K0XpEfreoxidOB9STdBTwCfC8iLgeQdB5wBWn78KUl7Qh8EbiGlG9iXeAVUhKhF4FjgIWS3gd8PCJ+V3HZzczaM4gpsPV5b1p4mpRsrWYN4JkW5x4GfKwh/jP562M5H8+WwO/bLmCDqiuJTwObRMQWOdPcocDlkpYkJR06FlgamBoRxwFI+gYwOyIOkrQr8P18/dnAyxHxlVY3q89Mt8WkTZk8ce1KfzgzM4BY2DIXWidmAFMkrQP8kVQRvKfxJEkbAJOAW+uOTQJeiYjXJK0MvB34cpHCdHPg+gpgV0lLkbYCvzEi5jU5b0fgBwARcR2wkqTl27lBREyPiKkRMdUVhJl1TYkD1xGxADgOuAp4ELgwIu6XdIqkA+pOPRy4IGKxgY6NgJmS7gauB06vnxXViW4mHXo1N332JLUoWo3GD6Y/zsxs6JW8d1Pulr+84djJDd9Pa3LdLcCmZZal6pbES8Cydd9fAHwAeAeplmx2zo3Ae+Fv+a7nRsSLTc4zMxse+qL9R4+ptJKIiD8DN0u6T9IZwNXATsC1ef4vpCbRxnl14KHANGBqTl96OnBEPu+XwLvyee+ostxmZoNS8orr4aTy7qaIaBxwWanh9eeAbRrOecPCkYh4GNis3NKZmZWgB9/82+VtOczMiip3dtOw4krCzKyoHhxraJcrCTOzopyZrvfMp/x/tKU1rvSYNVVlkHvooYsqifvqvw+020rnnrujmnzB1/5pSiVxH16iuq6GcRVkWAS4Y+FzlcStMntc33CeCe+WhJmZtRIeuDYzs5bckjAzs5Y8u8nMzFpyd5OZmbU0grubupq+VNI0SZ/Mz4+UtNogr3d2OjMbfqKv/UePGcoc10cCTSuJnAi8mZ1xdjozG25G8AZ/hbqbJE0GrgRuJ2U/ehh4P/AA8FNgl3zqeyLi0brrDgamAj+SNA/YgbRv+rnAHsCZkv6OlI1uQY73aZydzsyGoVjggev+bAAcFRE3SzqXRTmtX4yIbSW9H/gvYL/aBRFxkaTjgE9GxEwASQCvRsSO+ftngHVyhqUVIuKFgbLT1Wem23TSJqw1ca0SfjwzswH0YAuhXWV0Nz0VETfn5z8kZZaDRUmFfkJqKbTjp3XP7yG1NN5Hak0MqD4znSsIM+saj0n0q7EKjSbH261m/1r3fF/gm8DWwCxJnollZsPTCB6TKKOSWEtSraVwOHBTfn5o3ddb33BVP5nmJI0B1oyI64F/BlYAJvZ3jZnZUIm+aPvRa8qoJB4EjsiZ5FYEzsrHl5J0O/AJ4MQm150HnJ0zzS3d8NpY4IeS7gVmA1+LiBdwdjozG45GcEuijC6cvog4pv5AHoT+ZkR8vv54feLuiPg58PO6lyfXvTafRWMb9dc7O52ZDT+e3WRmZi31YAuhXYUqiYh4AtikyfHJReKamfWSCFcSZmbWilsSvWfckO44MnhLjqnmn6KqDHLj/+NblcQFGHfAUdXErej/43kVZEGsGUOrHWqKWX7MUpXEjQqzx73Q91plsQtzJWFmZq304tTWdrmSMDMraoErCTMza8EtCTMza82VhJmZtdR7+/a1bSgz022Yt9eYLWm9fq65XNIK3SulmdngjOS9m4ayJXEQcGlEfK6/kyJin8ZjSvt+KKIH9901sxEnRvDAdaGWhKTJkh6SdL6keyRdJGkZSU9I+pKkO/LjLQ3X7QOcAHxI0vX52CWSZkm6PycPqp37hKSV870elPQt4E5gzSJlNzMrTd8gHj2mjO6mDYDpEbEZ8CINmemAM0mZ6f4mIi4Hzibt7lpLcfrBiNialNb0eEkrtbjX9yNiy4h4soSym5kVNoJzDg2rzHTHS7obuI3USpjS5JwnI+K2VgEkHS1ppqSZT7zsOsTMusQtiX4VzkwnaWdgN2CHiNiclENifJNT/9rk2KKb1KUvnTxx7X4LbWZWlrJbEpL2kjRH0qOSPt3k9SMl/V+e/HOXpA/VvXaEpEfy44iiP9tQZqartzzwfES8ImlDYPsSymVm1h0ltiQkjSWlbt4b2Bg4XNLGTU79aURskR/n5GtXBD4HbAdsC3xO0qQiP9pQZqardyWwRI5xKqnLycysJ/QtaP/Rhm2BRyPisYh4HbgAOLDNouwJXBMRz0XE88A1wF6d/Ew1Q5mZrv75a6Ra8w3qclPMpUnuCjOzoTaYAek8e/PoukPTI2J63ferA0/Vff80qWXQ6N2SdgIeBk6MiKdaXLt6+6V7I6+4NjMrKtT+qalCmN7PKc2CNY7r/hL4SUS8JukY4Hxg1zavHZRC3U0R8URENM1MFxFzi8Q2M+sVJQ9cP83i68DWAJ5Z7H4Rf849MADfAbZu99rB6q3MPGZmw1D0qe1HG2YAUyStI2lJ4DDgsvoTJK1a9+0BpLFhgKuAPSRNygPWe+RjHXN30yC8FK9XFnuFcRMqifvcHe2NlA1WVdnjAFa57LuVxH1ly5MriTu/wmxsf2VhJXGXqijjXZXGMn+oi9BSmYvkImKBpONIb+5jgXMj4n5JpwAzI+Iy0rqyA4AFwHPAkfna5ySdSqpoAE6JiOeKlMeVhJlZQX0L2x+TaEfeleLyhmMn1z3/V+BfW1x7LnBuWWVxJWFmVlCb3Ug9yZWEmVlBMXI3gXUlYWZWlFsSZmbW0kiuJIZkCmxDhrobJE1tcs7Okn7V/dKZmQ1O30K1/eg1bkmYmRUUg1hx3WtKaUl0mqGuziH59YclvaNJ/GmSfiDpurz97YfLKLeZWRmcdKg9g85QV2eJfM4JpG1um9kM2JeUwOhkSauVVnIzswL6Qm0/ek2ZlUSRDHW/yF9nAZNbnHNpRMzLe0JdT9pOdzHOTGdmQyFCbT96TZmVRJEMdbWNqhbSepykVfxFB5yZzsyGQMl7Nw0rZVYSZWSo68+BksZLWgnYmUV7k5iZDSnPbmpPLUPdt4FHSBnqPs6iDHVjSJVHp+4Afg2sBZwaEYW2vzUzK0svjjW0q8xKotMMdTvXPZ9LHpOIiBuAG+ouezgi6rM5mZkNC7041tAur5MwMyvIezcNICKeoEn+6br81EXjTysjjplZFdzdZGZmLbm7qQctqCBb2JKqLpvXswteqSTutX+aUknccRU2r6vKIHfU7FMqifv1raopL1BZ/rg58WIlcV+PajIhAjz56tzKYhe1sAentrZrxFYSZmbd4paEmZm15DEJMzNraQRPbnIlYWZWlFsSZmbW0sIRXEmUmU/ivjJimZn1mkBtP3qNWxJmZgX1jeBBiTJ3gR0r6TuS7pd0taSlJX1Y0gxJd0v6uaRlACSdJ+lsSb/L2ej2y8ePlHSppCslzZH0uXz8VEmfqN1I0hckHV9i2c3MOtaH2n70mjIriSmkzfzeCrwAvBv4RURsExGbk3aJParu/MnAO0nZ5s6WND4f3xZ4L7AFKa3pVOC7wBEAksYAhwE/KrHsZmYdG8ndTWVWEo9HxF35eS3D3Ca5tXAv6Y3/rXXnXxgRfRHxCPAYsGE+fk1E/Dki5pEy1u2Y94b6s6QtgT2A2RHx58YC1Geme/LlP5T4o5mZtdY3iEevKXNM4rW65wuBpYHzgIMi4m5JR5KSBdW0k8mu/vtzgCOBNwPnNitAREwHpgPsv9Z+I7iX0MyGk4U92EJoV5ktiWaWBZ6VNI7Ukqh3iKQxktYD1gXm5OO7S1pR0tLAQUAtb/bFwF7ANsBVFZfbzKxtbkl07rPA7cCTwL2kSqNmDvBb4E3AMRHxak5SdBPwA+AtwI8jYiZARLwu6XrghYhYWHG5zcza1otjDe2qJJ9ERHyl7uWzWlx2c0Sc2OT4nyLiuMaDecB6e+CQAkU1MyvdCN4EtvLuplJI2hh4FPhNHug2Mxs2RvIU2CFZTBcRR7Y4fh5psLvx+AOkcQszs2FnJPd/e8W1mVlBfeq9FkK7Rmwl8XoFY9tR4YbAE8aOH/ikDjy8RDWfceZVOE9jfkW/56oyyH3izmoy3gH8epN/ryTuhKXGVRJ31vO/ryQuwImTtqksdlFl/8VK2gv4Oik54TkRcXrD6ycBHwIWAP8HfDAinsyvLSRNFAL4Q0QcUKQsI7aSMDPrljI/MkkaC3wT2B14Gpgh6bLc7V4zG5gaEa9IOhb4MnBofm1eRGxRVnl6YuDazGw461P7jzZsCzwaEY9FxOvABcCB9SdExPUR8Ur+9jZgjTJ/nnquJMzMCip5dtPqwFN13z+dj7VyFHBF3ffj8/ZEt0k6aPA/zeLc3WRmVtDCQYxbSzoaOLru0PS8pdDfTmlyWdNhD0nvA6aSNkutWSsinpG0LnCdpHsjouPBIlcSZmYFDWZMon6PuRaeBtas+34N4JnGkyTtBnwGeGdE/G3vvIh4Jn99TNINwJZAx5VEad1NknaW9Kuy4rW4x0F5YZ2Z2bARg3i0YQYwRdI6kpYkpUa4rP6EvCP2t4EDIuJPdccnSVoqP18ZeDtQP+A9aL02JnEQ4ErCzIaVMgeuI2IBcBxpI9MHSWkV7pd0iqTadNYzgInAzyTdJalWiWwEzJR0N3A9cHrDrKhBG7C7SdIE4EJSk2cscCop/8PXgQmkLcL/vuGaacA6wKrA+sBJpH2X9gb+COwfEfMlbQ18Nf+wc4EjI+LZvDPsN4FVgFeADwMrAgcA75T078C7i/SzmZmVpexVQxFxOXB5w7GT657v1uK6W4BNyyxLO2MSewHPRMS+AJKWJ83RPTQiZkhaDpjX5Lr1gF1In/xvJb2p/7Oki4F9Jf0a+AZwYET8n6RDgS8AHyT11x0TEY9I2g74VkTsmmvLX0XERYV+ajOzEvXiFuDtaqeSuBf4iqQvAb8ipSZ9NiJmAETEiwB647L0K3Jr4V5SC+TKuniTgQ1IO8dek68dS8o9MRF4G6kZVYu1VDs/TP2sgY1XeCtrTFxzgCvMzIobzOymXjNgJRERD+duoX2ALwJX0974y2v5+j5J8yOidk1fvq+A+yNih/qLcsvkhU5WDNbPGthzzb2dmc7MumIktyQGHLiWtBrwSkT8EPgKaWxhNUnb5NeXldTJVNo5wCqSdshxxkl6a26ZPC7pkHxckjbP17zE4omLzMyGXMmzm4aVdt7cNwXOkNQHzAeOJbUCvpFTjM4Dmg6i9CdnmjsY+O88zrEE8F/A/aRUp2flAepxpGXpd+ev35F0PHCwB67NbDgYyUmH2uluuormOaW3b/j+hvwgIqY1xJhY93xa3fO7gJ2a3PNx0oB54/Gb8RRYMxtmRnJ3k1dcm5kV5KRDZmbW0qjubjIzs/65u6kHLdPRhKv+NVkLUpq5C16uJO64ihKvj2FsJXEB/lpR472qEleVPQ5g3/v+o5K4Z255bCVxN1q2urVJs3ipsthF9eKspXaN2ErCzKxb+kZwNeFKwsysIHc3mZlZS57dZGZmLXl2k5mZtTSSxyS6nnSoSAY7SSdIWqbsMpmZFTGS927qtcx0JwCuJMxsWOkbxKPXlNbd1GEGu21Jm/rVNgr8QETMkTQW+BKwJ6ny/Q5pU8HVgOslzY2IXcoqu5lZESO5u6nMMYlOMtg9BOwUEQsk7QacBryblDhoHWDL/NqKEfGcpJOAXSJibonlNjMrxLOb2tNJBrvlgfMlTSG1GMbl47sBZ+eE4ETEc+0UoD4z3RaTNmXyxLWL/kxmZgMayS2J0sYkIuJhYGtSZfFF4F0MPE5zKnB9RGwC7A+Mz8fVxrXNyjA9IqZGxFRXEGbWLR64bkOHGeyWB/6Ynx9Zd/xq4Jja+ZJWzMedmc7Mhh0PXLenkwx2XyZ1N50EXFd3/BxgfeAeSfNJA9dnkvJXXyHpWQ9cm9lwET3ZRmhPaZVEhxnsbiVVBjWfzccXACflR/09vgF8o5QCm5mVZIErCTMza2XkVhGuJMzMChvJs5tcSZiZFdSLA9LtciVhZlaQB657UBWpRhdGdZ8X1l1yxYFP6sAdC9tahzhoy49ZqpK4AEtVlGh0TlrPWboJS40b+KQOVZVm9IrZZ1US9z1bn1hJXIBxw3irObckzMyspYVuSZiZWSt94UrCzMxaGLlVhCsJM7PCRvIU2OE7EpRJukHS1KEuh5lZKzGI/3rNsK8kWsmJiczMhlzZG/xJ2kvSHEmPSvp0k9eXkvTT/PrtkibXvfav+fgcSXsW+sHoUneTpM8C7wWeAuYCs4D9gNuBXYAVgKMi4nd5M8DvARsDD5Ky1tXivAx8lZSx7v8BN3Wj/GZm/VlY4iTY/AH4m8DuwNPADEmXRcQDdacdBTwfEW+RdBgpk+ehkjYGDgPeSsrkea2k9SOi47xIlbckclfRu4EtgX8A6ruOloiIbUm5qz+Xjx1L2nJ8M+ALpBwVNROA+yJiu4hwBWFmw0LJLYltgUcj4rGIeB24ADiw4ZwDgfPz84uAv1daHHYgcEFEvBYRjwOP5ngd60Z3047ApRExLyJeAn5Z99ov8tdZwOT8fCfghwARcQ9wT935C4Gft7qRpKMlzZQ08/GXnyyp+GZm/YuIth9tWJ3U61LzdD7W9Jy8a/ZfgJXavHZQulFJ9Lf0+bX8dSGLd321+k2+2l+zqT4z3TrOTGdmXdJHtP2o/zCbH0c3hGv2ntn4ntjqnHauHZRuVBI3AftLGi9pIrDvAOffSBq/QNImwGYVl8/MrJDBdDfVf5jNj+kN4Z4G1qz7fg3gmVbn5AyeywPPtXntoFReSUTEDOAy4G5S99JMUtOolbOAiZLuAf4ZuKPqMpqZFbGQvrYfbZgBTJG0jqQlSQPRlzWccxlwRH5+MHBdpL6sy4DD8uyndYApFHwP7dZiuq9ExDRJy5BaCv8ZEd+pvRgRc8ljEhExj/RLeYOImNiFspqZDUqbYw3txlog6ThSps+xwLkRcb+kU4CZEXEZ8F3gB5IeJbUgDsvX3i/pQuABYAHwsSIzm6B7lcT0PDVrPHB+RNzZpfuamVWu7F1gI+Jy4PKGYyfXPX8VOKTFtV8gzQwtRVcqiYh4TzfuY2Y2FHpxJXW7vHeTmVlBI3nvJlcSZmYFlTkmMdyM2EpiqQombr1cYf6pd81frpK454+dW0ncXmxevx4LKok76/nfVxIXYKNl1xz4pA5UlUHux7O+VklcgKVXe0clcX9cQowyt+UYbkZsJWFm1i1OOmRmZi2N3CrClYSZWWEeuDYzs5ZcSZiZWUsLwwPXZmbWQi/O9mtXpRv8SbpE0ixJ99e2w5V0lKSHc+7q70g6Mx9fRdLPJc3Ij7fn49tKukXS7Px1gyrLbGY2WCXnkxhWqm5JfDAinsspSWdI+jXwWWAr4CXgOtLusABfB74WETdJWou0udVGwEPATnnTq92A00iZ7szMhgWPSXTueEnvys/XBP4J+G1EPAcg6WfA+vn13YCNUwY+AJaTtCxpn/TzJU0hzTQb1+pmubVyNMDUFTfnLRMnl/vTmJk10YsthHZV1t0kaWfSG/8OEbE5MBuYM0BZdoiILfJj9Zzu9FTg+ojYBNiftJNsU/XJPFxBmFm3DCYzXa+pckxieeD5iHhF0obA9sAywDslTcrZlOq7ja4Gjqt9I2mLujh/zM+PrLC8ZmYdWRh9bT96TZWVxJXAEjnD3KnAbaQ3+9OA24FrSYkxalnqjgemSrpH0gPAMfn4l4EvSrqZlIDDzGxYiUH812sqG5OIiNeAvRuPS5oZEdNzS+JiUguilp3u0CZxbmXRuAWkgW8zs2FjJO/dVHmO6yamSboLuA94HLhkCMpgZlYatyRKFBGf7PY9zcyqNJJbEl5xbWZWUC+2ENrlSsLMrKBenLXUrhFbSfwlXi895gS1XMdXWFUZ5Kqal/1C32uVxAUYy/xK4j75ajW/4xMnbVNJXIBZvFRJ3HEVDUdWlT0OYN4zv6ssdlHhSsLMzFrpxUVy7XIlYWZW0EjelsOVhJlZQW5JmJlZSwv7PCZhZmYtjOQpsF1bcS3pIEkbd+t+ZmbdMpKTDnWlksj7NB0ElFJJSPJGf2Y2bHircEDSZEkPSTo/79R6kaRlJJ2c043eJ2m6ctagnJ70NEm/Bf4FOAA4Q9JdktbLr39J0h05nek78nVjJZ2RY94j6SP5+M6Srpf0Y+De8n8VZmadcUtikQ2A6RGxGfAi8FHgzIjYJicFWhrYr+78FSLinRHxBeAy4FM5odDv8+tLRMS2wAnA5/Kxo4C/RMQ2wDbAhyWtk1/bFvhMRDRtkUg6WtJMSTP/8PIfBvmjmZl1pi+i7UevGWwl8VRE3Jyf/xDYEdhF0u2S7gV2Bd5ad/5PB4j3i/x1FjA5P98DeH/eKfZ2YCVgSn7tjoh4vFWw+sx0a01cq92fycyskJGcdGiws5saq8EAvgVMjYinJE1j8fSifx0gXm1vh4V1ZRHw8Yi4qv7EnA51oHhmZl3Xi91I7RpsS2ItSTvk54cDN+XncyVNBA7u59qXgGXbuMdVwLFS2ihJ0vqSJgyynGZmXePupkUeBI7IKUlXBM4CvkMaSL4EmNHPtRcAn5I0W9J6/Zx3Dimt6Z2S7gO+jddzmNkw1q2kQ5JWlHSNpEfy10lNztlC0q2S7s+Tfw6te+08SY/nCUR3SdpiwHu220ySNBn4VR6gHvb2WWuf0qvsKneB/UtFu6r24pS7sRXNzH5k3v9UEvegLK3SAAARdUlEQVSoCdUt/6lqF9jxFaWLv/DZOyqJC9XtAjtu5XVVNMbSS6/d9v9o8+Y92fH9JH0ZeC4iTpf0aWBSRPxLwznrAxERj0hajTTmu1FEvCDpPNL7+EXt3nMo0peamY0oXZwCeyBwfn5+Pmn9WWNZHo6IR/LzZ4A/Aat0esO2K4mIeKJXWhFmZt3UF31tPwp6U0Q8C5C//l1/J0vaFlgS+H3d4S/kbqivSVpqoBu6r9/MrKDBtBAkHQ0cXXdoekRMr3v9WuDNTS79zGDKJGlV4AfAEbEoK9K/Av9DqjimkxY6n9JvoME0k0bqAzjacXuzzP5d+HfR7d/FUD6AOcCq+fmqwJwW5y0H3Akc0k+snUnjE/3e02MSydEDnzIq4lYZu9fiVhm71+JWGbvX4g61y4Aj8vMjgEsbT5C0JHAx8P2I+FnDa6vmryKNZ9w30A1dSZiZ9Y7Tgd0lPQLsnr9H0lRJ5+Rz/hHYCTiyyVTXH+XdMe4FVgb+Y6AbekzCzKxHRMSfgb9vcnwm8KH8/IekbZOaXb/rYO/plkQyfeBTRkXcKmP3WtwqY/da3Cpj91rcUaftxXRmZjb6uCVhZmYtuZIwM7OWXEmYmVlLo76SkLRs3ua8aJwxkt5WRplaxH97O8eGS2wlaxaJMZLUZVfs99hwUPXfsvWWUVtJSNpU0mzSYpIHJM2S1PHeVJGWvf9naQV8o2+0eWxYxI40I+KSIjH6I+nNkg6QtL+kZlsYdBr3uGbbL5fg502Otb0TZyuSftPOscGo+m9Z0hRJF0l6QNJjtUfBmGNyagEr2WheJ/Ft4KSIuB7+lvluOlDkE9TVkt4N/CJKmjaWkzy9DVhF0kl1Ly0HxfZ7rjJ2dpukbSKivzwjgybpQ8DJwHWkTIbfkHRKRJxbQvg3AzMk3QmcC1xV5N9S0oaklL7LS/qHupeWY/EsjoONOx5YBlg5V2q17aeXA1brNG6d0v+W63yPlNP+a8AuwAdYVP6ORESfpLslrRURTnBfotFcSUyoVRAAEXFDCRnwTgImAAskvUr6w4+IWK5AzCWBiaR/q/rMfi/SfybAoY4N6Q3gI5KeJKWerf0+NisY91PAlnlhEZJWAm4hvakXEhH/LumzpFzrHwDOlHQh8N2I+H3/Vze1AbAfsAKwf93xl4APFyjqR4ATSBXCLBa9yb4IfLNA3Joq/pZrlo6I30hSRDwJTJP0O1LFUcSqwP2S7qAu1XFEHFAw7qg2atdJSLqYtAHWD/Kh95Fydb9hf/bhQNLaEfGkpGVJ/7O+XHbs/HwMMDEiXiwjbrPjtXsViPsbYO+IeD1/vyRweUTsViRuwz02J1USewHXA9sD10TEP3cYb4eIuLWs8tXF/XhElNXt2BWSbgbeQepuuw74I3B6RGxQMO47mx2PiN8WiTvajeZKYhLweWBH0qekG4FpEfF8CXGnUNeVEBE3FomZ425CqtBWzIfmkrYALtwPK+nHwDHAQtKn0uWBr0bEGR3GWy4iXpS0YrPXI+K5jgub4n8f2JS0uVmQErHcATyc43+1QOzjSRunzSWl0r0kIubnyvORiOgv9W5/cdcnpft9U0RsImkz4ICIGHDvnAHifgz4UUS8kL+fBBweEd/qMN5W/b0eEXd2ErfhHtuQUiGvAJxK6iI7IyJuKyH22sCUiLhW0jLA2IioJr3fKDFqK4kq5L7yTwBrAHeRPn3e2sl+KU1i3wJ8pmEM5bSIKDwLRdJdEbGFpPcCW5P2mJ/VabeQpF9FxH6SHie9idf3N0dErFuwvP12S0TE5wvEPoXUtfSG1o6kjSLiwQ7j/pbUTfbtiNgyH7svCibyqv3bNRybXbtHB/FqXbDjganA3aR/v82A2yNixyLlbbjXhIj468Bnth3vw6TdX1eMiPUkTQHOjog37HVk7Ru1YxL5k90ngcnU/R4KvqF/AtgGuC0idsmDlh2/YTWoYgylZpykcaStg8/Mn5w7/vQQEfvlr5VM8SxSCbQR+2RJW0k6kFTB3Vz79NxpBZEtExF3SIuNzy4oEK9mTO7bDwBJY0ljTR2JiF1ynAtIORnuzd9vQvr/pbA8YeK7pPGwtXLX3kci4qMFQ38M2Ba4HSBSjud+M7fZwEZtJQH8DDib1KWwsKSYr0bEq5KQtFREPCSpUD9rncfygGr9GMrjJcU+G3iC9KnxxtxkLzwmAeV2v0n6JemNu6kyBijz7/gfgV/kQ9+T9LOi3ULAXEnrkcsv6WDg2YIxAa4CLpR0do59DHBlCXE3rFUQABFxnxZtN13UfwF7knIjEBF3S9qphLivRcTrtYpY0hL08/di7RnNlcSCiDir5JhPS1qBtD7gGknPA8+UFPuDpFZJ7c3rRuDIokFzX/v/RsTqdcf+QJqZVDR20+43oNPW2leKlqkN7yHNnHoVQNLppAkORSuJj5GmWG8o6Y+kCv59BWNC6hr8CHAsqVvoatIHn6IeVMpP8EPSG+37SOMIpYiIpxpaVWV8UPutpH8Dlpa0O/BR4JclxB3VRu2YhKRpwJ9IGZxeqx0vOqhaF/+dpAHgK2uzcArGO6RJlqk3HOsw9o0RUcYnuca497Ko+22LWvdbRBxa9r3KIukK0sBvbSB4BeCHtS60EuJPAMYM98HUvA7jWFLyGkgfSs6qVZ4FY18EfBU4k/TB4XjSzMLDCsYdAxxFmr4sUivrnArWeYwqo7mSaNZVU8ag6o6k2RXfk7QKaTpp4W4hSXdGxFYDHesw9meBecBPWXx+edFZSDMiYhtJdwHbRcRrzQZaO4j7dmAasDapNVybw1/o3y7HvoRUsV1D+gS9O3AT6QMFEXF8h3HfBJwGrBYRe0vaGNghIr5bsLxTgC8CG7N4l17h30VVJK0MfB3YjUWtn0/U1r3Y8DJqK4kq5Fk3U4ENImJ9SasBP4uIjvdBkrQ3sA+pn/yndS8tB2wcEdsWKXO+R1UV5sWktQYnkLqYngfGRcQ+BeM+BJxImq77t26KMt5kJB3R3+sRcX6Hca8grTT+TERsnvvLZ0fEpp3Eq4t7E4tWL+9PXr0cEYUWpjWpiIFhX/lU9uFhNBt1lYQW3xrhDSLiF/29PkDsu4AtgTvrpjne0+lU0nz95sAWwCmkrShqXgKuL7quI99jfGM3QrNjg4i3TmPrqczuN0m3R8R2RWIMEH9JYENSS2JOSd2FtVbV7Lq/jTJaVbMiYmtJ99YqHEm/i4h3FIxbZUX8300O/wWYGRGXFohbWZlHs9E4cF3bGuHvSPsWXZe/3wW4gUUDw514PSKiNn20jCmqEXE3cLekecClEfHaQNd04Bagsduq2bF2XQRsLek3tTnqUcKqVy1a6HW9pDNI/1b140llLPTah7Sv1+9Jn0TXkfSRiLiiYOi/Km0fUvvb2J70xljUq7kv/hFJx5FWL5cx7fMvJfzMrYwnVcK18bR3A/cDR0naJSJO6DBulWUetUZdJRERH4C04IvUXfNs/n5Viu95c6GkbwMr5IU9HwS+UzBmzd7AGZJuBC4gbTxXaJ690u6pq5Nmg2wJi20St0yB0GNy19v6WnzjQKDQiujGnUmn1oel81lT9b4K7BIRjwLkaau/Boq++ZxEmvK5ntK2FKtQzv5YJ5D+rY4nrV7elbRivKjKKmLgLcCutb9fSWeRxiV2B+7t78IBVFnmUWvUVRJ1JtcqiOx/gfULxnwNuJa0xmAD4OSIuKZgTCBVbkoL3vYmTdP8lqRrIuJDBcLuSZpGuwbpzbHmJeDfCsQ9jLQwr3HjwEJqC70q9qdaBZE9Rh60LiIi7sxdbhuQKuM5ETG/hLi1HXZfJo1HlKXWnbd1/irKq4hXJ20eWGtJTSAN6C+UVKSlXCtzFR8eRq3RXEncIOkq4CekP6TDSBu5FfEm0rqA2jbT1xaMt5i8EvoKUnmXJr0Rd1xJ5EHY8yW9OyKa5TvoNO4c4Et5PKa05n+zVknDfTves6nO/ZIuBy4k/Z4PIW0d/g/5Hh11RyqthN6HRSv895DUcZm7sLDwVyy+pUoAL0raIiLuKhj7y8Bdkm7I8XcCTsvds0X+nzkqIhbLSyHJg9YFjbqB63r5f/zaAN+NEXFxCTHFom2mp5LebDrdZro+7l6kiqw2dvJT4OoiXU5VvelWGLeyPZvq7vG9/m8RH+ww7uXAq6TulL66gB2VWS12PK2LW2gMSGnTx6mkLjIB+wIzyGMJEfHlgvFXA/4JeIjUkng6Cm6E2WKa+KyI2LrVNTaw0dySqH0qLDJQ3SxmSPof4H9Ie/NMAi7KXUMdbTOdfYDU6vlIbfBa0pdIK247VVpXUDfillEJtHGPMrts6q1RZJZbo1olkD99z4uUTa7WYlmqhFusBGwVeUv6XEFfRPrUP4vUGuiISl6Jr4oSO1ky6loSkm6KiB0lvcTizfXCSVVU0TbTOXazT0mFptf2qtyF8HXSm0uQ3mBObOxq6DD2eNKq3bey+OK0jloQdXG/BPwmIq4uVsI3xL0N2K3uzXwiqYVZaHdgSQ8Cm8einB1LAXdFxEYqsMtsjlXqSnylzRgPAg4g7weVvQRcEBG3dFpWG4UtichbHUdEFZ92Vwb+IRq2mY6UWrGjbR0kHUvag2ZdSffUvbQscHPHJV38HpW86Vb4Zv5j0ky0d+XvDyO1sspYO/EDUhfInqS1Ke+lnD2LbgMuzh8Y5lPCh5JsfNQloIqIl5XyKBT1Y1L62dq6hf2Bn+SWywMFY5e6EWZEXJpnK/5LRJxWsGzWKCL8GMYP0gK0yaQ3wbXrHiuWeI/bSP3DS+TH+0i5A4Zr3DfEIH0qLeN3MTt/vSd/HQdcV0Lcx0g5GVTy38fNpG6h2vdTSTlMyoi9Nalb6ATS3kpllfliUsKhaaQ9oS4lZRYsGvf6Mn+3fqTHqOtusjdqtoJZ0m0Rsf0wjXs6afpkbWbaoaR++G9CsT2nJN0REdvm9SgfJY0t3RHFtyi5ipRytW/AkwcXdyppEsMzpN/FasChETGrzPtUpeSV+F/IsRr3IPM6iQJcSVhlb7oVxq1t+VH74y0t810eVP05KT3qeaTEOJ+NiG93GjPHPQ9Yl7Qor36hV6Fpu5IOIe12uhap+217UnlH3RujFmXVqxdRQmbI0cyVhFX2plth3KVJn/J3zLF/R3nbWC9F2iZiMqmrqVbWUwrGbTp9NwrO2KpNXlDaffg00qr0f2tswZl1ypWEVfamW2HcC0mr2n+UDx0OrBAR/1gkbo59Jan107hJXOOWIMNCbaaRpC8C90bEj4vOPuplkvbljTPTClXwo50rCavsTbfCuHdHxOYDHesw9n0RsUnROHXxKl0ZnWf1/JGUm2FrUl6QO8r4XfQapRSuy5AWnJ5D2hvrjog4akgL1uNG3RRYa2qDhjeV6yXdPYzjzpa0fUTcBiBpO0qaDgzcImnTqMvvXFDVKVf/EdgL+EpEvKC0UeWnKr7ncPW23PV2T0R8XtJ/UvJi2dHIlYRBdW+6VcXdDni/Ui5uSIO2D+ZFWhEdLDCsXUv6f+IDkh4jDTDX1jN0tGgxKl4ZHRGvUPdGGGnTymdbXzGizctfX8nbfvwZWGcIyzMiuJIwqOBNt+K4e3V4XX9KyWHdj9+QuoRqC9+WJm2PXWhltC3mV0o5yb9MGlOC1O1kBXhMwpC0dn+vR8MK8qGO24vUJAtds2PWuTxR4ljSpp2lznobzdySsMrerEdTJdCGv0raqrZ+IS+CmzfANTY455P2a6qlRz0c+D5p3MY65JaEWRf0+sroXlDlrLfRbMxQF8BslFgH2JLUHXINMId+psZaR2Yr5Q4HSp/1Nmq5JWHWBV4ZXb28vfkGwGITJUhJnopMlBjVPCZh1h211dv7AmdH2t562hCWZySqYtbbqOeWhFkXeGW09SpXEmZdkBMB7UXaX+mRvDJ60yg5U51Z2VxJmJlZS57dZGZmLbmSMDOzllxJmJlZS64kzMysJVcSZmbW0v8H7oHQbf3PfDEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# create a correlation matrix\n",
    "corr=df.corr()\n",
    "\n",
    "# plot the correlation matrix\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features 'ppltrst' pplfair' and 'pplhlp' seem to have some correlation, and in the real world seem similar. For these reasons, the 3 features will be combined into one feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine ppltrst, pplfair and pplhlp into one feature \n",
    "means = df[['ppltrst','pplfair','pplhlp']].mean(axis=0)\n",
    "stds = df[['ppltrst','pplfair','pplhlp']].std(axis=0)\n",
    "df['trust_fair_help'] = ((df[['ppltrst','pplfair','pplhlp']] - means) / stds).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.040780141843971635\n",
      "Percent Type II errors: 0.17212220403709766\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06134969325153374\n",
      "Percent Type II errors: 0.18895705521472392\n"
     ]
    }
   ],
   "source": [
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "Z = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'ppltrst', 'pplhlp', 'pplfair'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "Z = pd.concat([Z, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(Z.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "Z_train, Z_train = Z[:offset], Z[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "Z_test, y_test = Z[offset:], y[offset:]\n",
    "\n",
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(Z_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(Z_train)\n",
    "predict_test = clf.predict(Z_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with the combined feature of 'trust_fair_help', the model does not improve much, and is more error prone against the null hypothesis in the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03927986906710311\n",
      "Percent Type II errors: 0.15766503000545554\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.0687116564417178\n",
      "Percent Type II errors: 0.19141104294478528\n"
     ]
    }
   ],
   "source": [
    "# We'll make 1000 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(Z_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(Z_train)\n",
    "predict_test = clf.predict(Z_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The errors lowered for the training set, but increased with the test set. This likely means the model is off, and we need to readjust the features or other attributes of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.040780141843971635\n",
      "Percent Type II errors: 0.1638025095471904\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.0687116564417178\n",
      "Percent Type II errors: 0.18650306748466258\n"
     ]
    }
   ],
   "source": [
    "# We'll make 1000 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'exponential'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(Z_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(Z_train)\n",
    "predict_test = clf.predict(Z_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the loss function reduced Type II errors, but slightly incereased the Type I errors in both the training and test sets. However, 1000 iterations were kept in this run, showing that the model is better fit with the exponential loss function. How do the cross validation scores look?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([2.37183595, 2.23698378, 2.17250705, 2.06505227, 2.09717894,\n",
      "       2.14725399, 2.13024211, 2.11967516, 2.08901405, 2.11388183]), 'score_time': array([0.005651  , 0.00651121, 0.0054059 , 0.00711393, 0.0055871 ,\n",
      "       0.00557399, 0.0056572 , 0.00669312, 0.00486183, 0.00477695]), 'test_score': array([0.74877451, 0.64460784, 0.70098039, 0.70429448, 0.75798526,\n",
      "       0.77027027, 0.72850123, 0.73218673, 0.75184275, 0.74692875])}\n"
     ]
    }
   ],
   "source": [
    "# run 10-fold cross validation on gradient boost model\n",
    "from sklearn.model_selection import cross_validate\n",
    "cv_results = cross_validate(clf, Z, y, cv=10, return_train_score=False)\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7286372211340634"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model shows significant overfitting, how does the max depth affect the overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.007637752318603383\n",
      "Percent Type II errors: 0.06587561374795417\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.09693251533742331\n",
      "Percent Type II errors: 0.17177914110429449\n"
     ]
    }
   ],
   "source": [
    "# We'll make 1000 iterations, use 4-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 4,\n",
    "          'loss': 'exponential'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(Z_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(Z_train)\n",
    "predict_test = clf.predict(Z_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the model with 4-level depth, the error scores in training set drop dramatically, while the errors in the test set decreased by 1%. How do the cross validation scores look for 4-level depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([5.75188303, 5.5016799 , 5.572788  , 5.34447002, 5.44242096,\n",
      "       5.25591111, 5.45244789, 5.66374397, 5.33139992, 5.22642779]), 'score_time': array([0.01163411, 0.00997591, 0.01055717, 0.01034617, 0.01038885,\n",
      "       0.01004386, 0.01052189, 0.01073289, 0.00898004, 0.00932193]), 'test_score': array([0.74877451, 0.57107843, 0.65441176, 0.70674847, 0.74078624,\n",
      "       0.76044226, 0.72358722, 0.64127764, 0.74692875, 0.73955774])}\n"
     ]
    }
   ],
   "source": [
    "# run 10-fold cross validation on gradient boost model\n",
    "from sklearn.model_selection import cross_validate\n",
    "cv_results = cross_validate(clf, Z, y, cv=10, return_train_score=False)\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7033593024719874"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation score shows very little decrease in overfitting with a more in-depth model. This means the increase in error is not coming from overfitting, but from another error source. It is possible that the feature engineering process created more bias in the dataset. For example, it could be that 'ppltrst' is a good indicator of whether someone has a partner, but 'pplfair' is not. What happens when the max depth of the model is increased?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.09447852760736196\n",
      "Percent Type II errors: 0.16809815950920245\n"
     ]
    }
   ],
   "source": [
    "# We'll make 1000 iterations, use 8-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 8,\n",
    "          'loss': 'exponential'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(Z_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(Z_train)\n",
    "predict_test = clf.predict(Z_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the max depth to 8 levels reduced all errors in the training set to 0, and reduced the Type II errors in the test set by 1%. This improvement shows that the errors are likely coming from a lack of sub-sampling, which more levels helps to ameliorate. What is the optimum depth level for this model?     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Results for max depth of 2\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.040780141843971635\n",
      "Percent Type II errors: 0.1638025095471904\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.0687116564417178\n",
      "Percent Type II errors: 0.18650306748466258\n",
      "\n",
      "\n",
      "Results for max depth of 10\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.08834355828220859\n",
      "Percent Type II errors: 0.17423312883435582\n",
      "\n",
      "\n",
      "Results for max depth of 18\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.09079754601226994\n",
      "Percent Type II errors: 0.17668711656441718\n",
      "\n",
      "\n",
      "Results for max depth of 26\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.15828220858895706\n",
      "Percent Type II errors: 0.14969325153374233\n",
      "\n",
      "\n",
      "Results for max depth of 34\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.14846625766871166\n",
      "Percent Type II errors: 0.147239263803681\n",
      "\n",
      "\n",
      "Results for max depth of 42\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.150920245398773\n",
      "Percent Type II errors: 0.15337423312883436\n",
      "\n",
      "\n",
      "Results for max depth of 50\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.147239263803681\n",
      "Percent Type II errors: 0.15337423312883436\n",
      "\n",
      "\n",
      "Results for max depth of 58\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.14846625766871166\n",
      "Percent Type II errors: 0.15460122699386503\n",
      "\n",
      "\n",
      "Results for max depth of 66\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.150920245398773\n",
      "Percent Type II errors: 0.14846625766871166\n"
     ]
    }
   ],
   "source": [
    "# create a range of max depths to test\n",
    "for md in range(2, 72, 8):\n",
    "    # We'll make 1000 iterations, use 8-deep trees, and set our loss function.\n",
    "    params = {'n_estimators': 1000,\n",
    "              'max_depth': md,\n",
    "              'loss': 'exponential'}\n",
    "\n",
    "    # Initialize and fit the model.\n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "    clf.fit(Z_train, y_train)\n",
    "    predict_train = clf.predict(Z_train)\n",
    "    predict_test = clf.predict(Z_test)\n",
    "\n",
    "    # Accuracy tables.\n",
    "    table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "    table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "    train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "    train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "    test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "    test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "    print((\n",
    "        '\\n\\nResults for max depth of {}\\n'\n",
    "        'Training set accuracy:\\n'\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}\\n\\n'\n",
    "        'Test set accuracy:\\n'\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}'\n",
    "    ).format(md, train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems a max depth of 34 is near the optimal level of max depth.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with the least amount of error found in this report has 1000 iterations and a max depth of 34 levels with an exponential loss function. Adding more levels to the model  \n",
    "\n",
    "The model seems significantly overfit, which could be fixed by running a PCA to find the components that explain the most variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
