{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Suppress annoying harmless error.\n",
    "warnings.filterwarnings(\n",
    "    action=\"ignore\",\n",
    "    module=\"scipy\",\n",
    "    message=\"^internal gelsd\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things get messy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is a good way to introduce the gradient descent algorithm because there is only one minimum â€“ one absolute best solution. In other algorithms, however, there may be both a global minimum (the lowest possible value over the entire surface) and many local minima, areas on the surface that are lower than the surface around them.\n",
    "\n",
    "When using the gradient descent algorithm with models that have local minima the algorithm can get 'caught' in one and converge on a less-than-optimal solution. One way to avoid this is to run the algorithm multiple times with different starting values.\n",
    "\n",
    "Still a bit confused? [This](https://www.kdnuggets.com/2017/04/simple-understand-gradient-descent-algorithm.html) is a useful resource for another explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopping rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the implementation programmed above, the only stopping rule involves the number of iterations. As you can see from the plot above, this might be a bit inefficient in this case. Modify the code above by adding a stopping threshold so that the algorithm stops when the difference in error between two successive iterations is less than .001. With that rule, how many iterations do you need before you stop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coefficients from sklearn: \n",
      " [[1.97959716]]\n",
      "\n",
      "Intercept from sklearn: \n",
      " [0.4585646]\n",
      "\n",
      "Coefficients from gradient descent algorithm: \n",
      " 1.979471785060328\n",
      "\n",
      "Intercept from gradient descent algorithm: \n",
      " 0.45847538101899793\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The new models has 333502 iterations. \n",
      "\n",
      "\n",
      "The final iteration with the stop value is: 0.089448354970692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Cost function for the linear regression that we will try to optimize.\n",
    "def LR_cost_function (alpha, beta, x, y):\n",
    "    '''Return the cost for a given line and data.\n",
    "    \n",
    "    Alpha and beta are the coeficients that describe the fit line line, while\n",
    "    x and y are lists or arrays with the x and y value of each data point.\n",
    "    '''\n",
    "    error = 0\n",
    "    n = len(x)\n",
    "    for i in range(n):\n",
    "        point_error = (y[i] - (alpha + beta * x[i])) ** 2\n",
    "        error += point_error\n",
    "    return error / n\n",
    "\n",
    "\n",
    "# Function we'll call each iteration (or step) of the gradient algorithm.\n",
    "def step (alpha_cur, beta_cur, learning_rate, x, y):\n",
    "    '''Move downhill from a current cost function to a new, more optimal one.'''\n",
    "    alpha = 0\n",
    "    beta = 0\n",
    "    n = len(x)\n",
    "    for i in range(n):\n",
    "        # Partial derivative of the intercept.\n",
    "        point_alpha = -(2 / n) * (y[i] - ((alpha_cur + beta_cur * x[i])))\n",
    "        alpha += point_alpha\n",
    "        \n",
    "        # Partial derivative of the slope.\n",
    "        point_beta = -(2 / n) * x[i] * (y[i] - ((alpha_cur + beta_cur * x[i])))\n",
    "        beta += point_beta\n",
    "        \n",
    "    new_alpha = alpha_cur - learning_rate * alpha \n",
    "    new_beta = beta_cur - learning_rate * beta\n",
    "    return [new_alpha, new_beta]\n",
    "\n",
    "# These constants correspond to the decision-points described above.\n",
    "# How many steps to take.\n",
    "stop = 1000\n",
    "\n",
    "# How far to move with each step.\n",
    "learning_rate = .005\n",
    "\n",
    "# Starting values for intercept and slope \n",
    "alpha_start = 0\n",
    "beta_start = 0\n",
    "\n",
    "# Time to make some data!\n",
    "x = np.random.normal(0, 1, 100)\n",
    "y = x * 2 + np.random.sample(100)\n",
    "\n",
    "# Fit an true minimum regression using solved equations.\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x.reshape(-1, 1), y.reshape(-1, 1))\n",
    "\n",
    "print('\\nCoefficients from sklearn: \\n', regr.coef_)\n",
    "print('\\nIntercept from sklearn: \\n', regr.intercept_)\n",
    "\n",
    "\n",
    "# Now fit an iteratively optimized regression using your custom gradient\n",
    "# descent algorithm.\n",
    "\n",
    "# Storing each iteration to inspect later.\n",
    "all_error=[]\n",
    "\n",
    "# Provide starting values.\n",
    "alpha = alpha_start\n",
    "beta = beta_start\n",
    "\n",
    "#Run the algorithm.\n",
    "for iter in range(1000):\n",
    "    \n",
    "    # Take a step, assigning the results of our step function to feed into\n",
    "    # the next step.\n",
    "    alpha, beta = step(alpha, beta, learning_rate, x, y)\n",
    "    \n",
    "    # Calculate the error.\n",
    "    error = LR_cost_function(alpha, beta, x, y)\n",
    "    \n",
    "    # add stopiing threshold\n",
    "    all_error.append(error)\n",
    "    \n",
    "# create new stop value\n",
    "errors=[]\n",
    "for a in all_error:\n",
    "    for b in all_error:\n",
    "        if (a-b)>=0.001:\n",
    "            errors.append(a)\n",
    "            \n",
    "        \n",
    "print('\\nCoefficients from gradient descent algorithm: \\n', beta)\n",
    "print('\\nIntercept from gradient descent algorithm: \\n', alpha)\n",
    "\n",
    "plt.plot(errors, 'o', ms=.4)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Error scores for each iteration')\n",
    "plt.show()\n",
    "\n",
    "z=len(errors)\n",
    "print('\\nThe new models has {} iterations. \\n'.format(z))\n",
    "print('\\nThe final iteration with the stop value is: {}\\n'.format(errors[z-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
